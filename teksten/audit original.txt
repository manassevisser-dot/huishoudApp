#!/usr/bin/env bash
# Phoenix Commander v3.1 â€” 2025-12-27
set -euo pipefail
PROJECT_ROOT="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
export PROJECT_ROOT
# ... (Je Bridge functies) ...
# Terminal Colors & Icons
RED='\033[0;31m'
NC='\033[0m'
ICON_FAIL='âŒ'

log_node() {
    node -e "const l=require('${PROJECT_ROOT}/scripts/utils/logger'); $1"
}

log_info() { log_node "l.info('$1')"; }
log_ok()   { log_node "l.ok('$1')"; }
log_warn() { log_node "l.warn('$1')"; }
log_err()  { log_node "l.error('$1')"; }
log_val()  { log_node "l.$1(l.TEXT['$2']('$3'))"; }

# DIT IS HET CRUCIALE DEEL: Exporteer de functies naar sub-processen
export -f log_node
export -f log_info
export -f log_ok
export -f log_warn
export -f log_err
export -f log_val

# ============ Orchestrator Dispatcher ============

cmd_full() {

    # 1. Draai de statische audit (wat je nu ziet)

    node scripts/maintenance/audit-orchestrator.js "$@"

    

    # 2. Draai de daadwerkelijke tests voor de coverage

    log_info "ðŸ§ª Starten van de Phoenix Test Suite (Jest)..."

    npm test -- --coverage --watchAll=false

}

cmd_all() {
    node scripts/maintenance/audit-orchestrator.js "$@"
}

_cmd_sanity() {
    node scripts/sync-aliases/index.js "$@"
}

_cmd_dedup() {
    bash scripts/maintenance/phoenix_dedup.sh src
}

_cmd_audit() {
    # Hiermee vertellen we phoenix-check: "Ik ben de baas, jij hoeft niet te loggen"
    export PHOENIX_INTERNAL=true
    bash scripts/maintenance/phoenix-check.sh
}

# ============ Dispatcher ============
case "${1:-}" in
  full)        cmd_full "$@" ;;
  all)         cmd_all "$@" ;; # Nu luistert hij ook naar 'full'
  audit)      _cmd_audit ;;
  dedup)      _cmd_dedup ;;
  fix|sanity) _cmd_sanity "$@" ;; 
  clean)       cmd_clean ;;
  ""|help|-h|--help) cmd_help; exit 0 ;;
  *) 
    echo -e "${RED}${ICON_FAIL} Onbekend commando: ${1}${NC}"
    cmd_help
    exit 1 
    ;;
esac
====
module.exports = {
    SYNC_START: 'ðŸš€ Phoenix Sync gestart...ðŸ”„',
    SYNC_ALIASES_FOUND: (n) => "Mapping: " + n + " ðŸ‘­ aliassen gevonden",
    SYNC_OK: 'Phoenix integriteit hersteld.ðŸ¤•',
};
====
module.exports = {
    FATAL: (msg) => "\nðŸš¨ FATALE FOUT: " + msg,
    HELP: "\nðŸ“‹ Phoenix Commander\nGebruik --dry-run voor simulatie.\n"
};
====
module.exports = {
    // === DEDUP ===
    DEDUP_START: "ðŸ” Start Deduplicatie scan...",
    DEDUP_REPORT_MOVE: "ðŸ“¦ Verplaatsen van deduplicatie rapporten naar base...",
    DEDUP_OK: "âœ… Deduplicatie succesvol afgerond.",
    DEDUP_SKIP: "âš ï¸ Dedup script niet gevonden of doelmap ontbreekt (skip)",

    // === PHOENIX-CHECK (AUDIT) ===
    AUDIT_START: "ðŸ›¡ï¸ Start Audit (phoenix-check)...",
    AUDIT_NOT_FOUND: "âŒ FOUT: phoenix-check.sh niet gevonden!",
    AUDIT_SUMMARY_FAIL: "âŒ Fout: Functie show_summary niet geladen uit reports.sh",
    AUDIT_STAT_HOUSEHOLD: "â„¹ï¸  Statistiek: Huishoudens met > 5 volwassenen krijgen speciale status.",
    
    // === LOCK LOGICA ===
    LOCK_STALE: "âš ï¸  Oude lock gevonden (>30 min). Opruimen en opnieuw startenâ€¦",
    LOCK_ACTIVE: "âŒ Phoenix audit is al bezig sinds:",
    LOCK_PID: (pid) => `â„¹ï¸  PID: ${pid}`,

    // === ORCHESTRATOR & CLEANUP ===
    STEP_START: (name) => `--- ${name} ---`,
    STEP_SKIP: (cmd) => `[DRY-RUN] Overslaan: ${cmd}`,
    STEP_FAIL: (name) => `Fout tijdens ${name}`,
    CLEANUP_RUNNING: "Rapporten opschonen (behoud laatste 5)...",
    CLEANUP_DONE: "Systeem opgeschoond.",
    CLEANUP_FAIL: "Opschonen mislukt of map is leeg.",
    
    // === GUARD DOG ===
    GUARD_CHECK: "ðŸ• Guard Dog: Checking file sizes...",
    GUARD_PASS: (file, size) => `âœ… PASS: ${file} (${size} KB)`,
    GUARD_FAIL: (file, size, max) => `âŒ FAIL: ${file} is te groot (${size} KB). Limiet is ${max} KB.`,
    GUARD_CRITICAL: "ðŸš¨ COMMIT AFGEKEURD: Los de bloating op voordat je commit.",
    GUARD_SAFE: "ðŸ¦´ Alles veilig: geen verdachte wijzigingen gevonden.",
    
    // === EXTRA GUARD DOG KEYS ===
    PRESET_CHECK: "ðŸ§ª Controleren van Babel presets...",
    ERR_BABEL_PRESET: "âŒ CRITICAl: 'metro-react-native-babel-preset' ontbreekt in package.json!",
    REMEDY_BABEL: "ðŸ’¡ Actie: Draai 'npm install --save-dev metro-react-native-babel-preset'",

    // Voorbeeld voor log_val2
    FILE_INFO: (file, size) => `Bestand ${file} is ${size} bytes groot.`,
    
    // === BABEL / JEST ERRORS ===
    ERR_BABEL_PRESET: "âŒ Babel Preset missing: 'metro-react-native-babel-preset' niet gevonden.",
    REMEDY_BABEL: "ðŸ’¡ Oplossing: Draai 'npm install --save-dev metro-react-native-babel-preset' en wis de jest cache.",
    
    // === CLEANUP & COMMIT ===
    COMMIT_START: "ðŸ§¹ Cleanup, prepare & commit",
    CLEAN_ARTIFACTS: "â€¢ Cleaning artifacts",
    CLEAN_BAK: "â€¢ Removing .bak backups",
    CLEAN_REPORTS: "â€¢ Pruning old reports (keep 5)",
    CLEAN_EXPO: "â€¢ Clearing Expo cache",
    RUN_CHECKS: "â€¢ Running lint/ts checks (non-fatal)",
    CHECK_ISSUE: (type) => `âš ï¸ ${type} issues (ignored)`,
    GIT_ADD: "â€¢ Git add",
    GIT_COMMIT: (msg) => `â€¢ Git commit: ${msg}`,
    GIT_COMMIT_NONE: "âš ï¸ Nothing to commit",
    GIT_TAG: (tag) => `â€¢ Create tag: ${tag}`,
    GIT_PUSH: "â€¢ Git push",
    COMMIT_DONE: (branch, tag) => `âœ… Done. Branch: ${branch}, tag: ${tag}`,
    
    // I DONT KNOW 
    FILE_TOO_LARGE: "Kritiek: bestand is abnormaal groot",
    DRY_RUN_COMPLETE: "Dry-run voltooid: Geen wijzigingen doorgevoerd.",
    CONFIG_BACKUP_SUCCESS: "Configuratie backup succesvol beveiligd",
    ADR_SAFETY_LIMIT: "Sync afgebroken door veiligheidslimieten (ADR-06).",
    CONFIG_BACKUP_SUCCESS: "Configuratie backup succesvol beveiligd",
    CONFIG_BACKUP_FAIL: "Kritieke fout: Configuratie backup mislukt. Operatie afgebroken.",
    // === IMPORTS ===
    IMPORTS_START: "ðŸ§© Phoenix Import Fixer: Aliassen rechttrekken...",
    IMPORTS_CLEAN: "âœ¨ Alle imports zijn al correct geformatteerd.",
    IMPORTS_FIXED: (count) => `ðŸ› ï¸  Succesvol ${count} imports hersteld naar aliassen!`,
  
    // === FINALE & DOCS ===
    FINISH: "Phoenix operatie voltooid.",
    KEYS_INDEX_NAME: "ðŸ”‘ PHOENIX CONSTANTS INDEX",
    KEYS_INDEX_GEN: (date) => `Gegenereerd op: ${date}`,
    REPORTS_LOCATION: (path) => `ðŸ“„ Zie rapporten in: ${path}`,
    // Zoek de regel FINISH_TIME en verander hem in:
    FINISH_TIME: (s) => `â±ï¸  Duur: ${s}s`,
};
====
const colors = require('./colors');
function writeStream(level, msg) {
    const isError = level === 'error' || level === 'fatal';
    const stream = isError ? process.stderr : process.stdout;
    stream.write(msg + '\n');
}
module.exports = {
    writeStream,
    info: (msg) => writeStream('info', "â„¹ï¸ " + msg),
    ok: (msg) => writeStream('ok', colors.green + "âœ… " + msg + colors.reset),
    warn: (msg) => writeStream('warn', colors.yellow + "âš ï¸ " + msg + colors.reset),
    error: (msg) => writeStream('error', colors.red + "âŒ " + msg + colors.reset),
    die: (msg) => {
        writeStream('fatal', colors.red + msg + colors.reset);
        process.exit(1);
    }
};
====
#!/usr/bin/env node
const fs = require('fs');
// ... rest van je code
const transports = require('./transports');
const sync = require('./constants/sync');
const audit = require('./constants/audit'); // NIEUW
const generic = require('./constants/generic');
const path = require('path');

// --- DE TERMALINK- HELPER (buiten het object voor intern gebruik) ---
const terminalLink = (text, filePath) => {
    const OSC = '\u001B]8;;';
    const ST = '\u001B\\';
    const url = `file://${path.resolve(filePath)}`;
    return `${OSC}${url}${ST}${text}${OSC}${ST}`;
};

const logger = {
    TEXT: { ...generic, ...sync, ...audit },
    
    isVerbose: process.argv.includes('--verbose') || process.argv.includes('-v'),
    isDryRun: process.argv.includes('--dry-run'),
    
    _startTime: null,
    startTimer: () => { logger._startTime = Date.now(); },
    stopTimer: () => {
        const duration = ((Date.now() - logger._startTime) / 1000).toFixed(2);
        transports.writeStream('info', "\x1b[2mâ±ï¸  Duur: " + duration + "s\x1b[0m");
    },

    info: (key) => transports.info(logger.TEXT[key] || key),
    ok: (key) => transports.ok(logger.TEXT[key] || key),
    warn: (key) => transports.warn(logger.TEXT[key] || key),
    error: (key) => transports.error(logger.TEXT[key] || key),
    /**
     * NIEUW: Speciaal voor rapporten met klikbare link
     * Gebruikt transports.ok voor de consistente Phoenix-styling
     */
    report: (reportPath) => {
        // 1. Maak de onzichtbare klikbare link van het pad
        const link = terminalLink(reportPath, reportPath);
        
        // 2. Haal de tekst op uit je constants. 
        // Omdat REPORTS_LOCATION een functie is, geven we de 'link' mee als argument.
        const message = logger.TEXT.REPORTS_LOCATION 
            ? logger.TEXT.REPORTS_LOCATION(link) 
            : `ðŸ“„ Zie rapporten in: ${link}`;

        // 3. Verstuur naar de transport (zonder extra ok-icoon, want die zit al in je string)
        transports.ok(message);
    
    },
    verbose: (msg) => { 
        if (logger.isVerbose) transports.writeStream('verbose', "\x1b[2mðŸ“£ " + msg + "\x1b[0m"); 
    },
    
    die: (msgKey) => {
        const msg = logger.TEXT[msgKey] || msgKey;
        transports.die(logger.TEXT.FATAL ? logger.TEXT.FATAL(msg) : msg);
    }
};

module.exports = logger;
====
module.exports = {
    reset: "\x1b[0m",
    red: "\x1b[31m",
    green: "\x1b[32m",
    yellow: "\x1b[33m",
    dim: "\x1b[2m"
};
====
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');
const logger = require('./logger'); // Als backup-helper en logger in dezelfde map (utils) staan.

/**
 * Phoenix Gold Backup Helper
 * Beveiligt de cockpit-configuraties vÃ³Ã³r elke grote operatie.
 */
const backupConfigs = () => {
    const rootDir = path.resolve(__dirname, '../../');
    const backupDir = path.join(rootDir, 'backups');
    
    if (!fs.existsSync(backupDir)) {
        fs.mkdirSync(backupDir, { recursive: true });
    }

    const timestamp = new Date().toISOString().replace(/[:T]/g, '-').split('.')[0];
    const filename = `config_backup_${timestamp}.tar.gz`;
    const fullPath = path.join(backupDir, filename);

    try {
        // 1. Maak de backup
        execSync(`tar -czf "${fullPath}" -C "${rootDir}" babel.config.js jest.config.js tsconfig.json package.json 2>/dev/null`);
        
        // 2. Retentie: Alleen de 2 nieuwste bewaren
        execSync(`ls -1t "${backupDir}"/config_backup_*.tar.gz | tail -n +3 | xargs rm -f 2>/dev/null || true`);

        // 3. Succes-log (Geen magic strings!)
        logger.ok(`${logger.TEXT.CONFIG_BACKUP_SUCCESS}: ${filename}`);
        
    } catch (e) {
        // 4. Kritieke failure (Geen magic strings!)
        logger.fail(logger.TEXT.CONFIG_BACKUP_FAIL);
        process.exit(1);
    }
};

module.exports = backupConfigs;
====
const { updateBetweenMarkers } = require('../utils');

function updateJson(content, aliases, markers) {
  const formatted = Object.entries(aliases)
    .map(([alias, paths]) => `      "${alias}": ["${paths[0]}"],`)
    .join('\n');
  return updateBetweenMarkers(content, markers.start, markers.end, formatted);
}

module.exports = updateJson;
====
const { updateBetweenMarkers } = require('../utils');

function updateJest(content, aliases, markers) {
  const formatted = Object.entries(aliases)
    .map(([alias, paths]) => {
      const cleanAlias = alias.replace('/*', '');
      const cleanPath = paths[0].replace('/*', '');
      return `      '^${cleanAlias}/(.*)$': '<rootDir>/${cleanPath}/$1',`;
    })
    .join('\n');

  return updateBetweenMarkers(content, markers.start, markers.end, formatted);
}

module.exports = updateJest;
====
const updateBabel = (src, aliases, marker) => {
  const content = Object.entries(aliases)
    .map(([key, value]) => {
      const val = Array.isArray(value) ? value[0] : value;
      if (!val || typeof val !== 'string') return null;

      const babelKey = key.replace('/*', '');
      let babelVal = val.replace('/*', '');
      
      // Zorg dat het pad altijd begint met ./ als het dat nog niet doet
      if (!babelVal.startsWith('./') && !babelVal.startsWith('../')) {
        babelVal = `./${babelVal}`;
      }

      return `          '${babelKey}': '${babelVal}',`;
    })
    .filter(Boolean)
    .join('\n');
  return updateBetweenMarkers(src, marker.start, marker.end, content);
};
====
function updateBetweenMarkers(content, startMarker, endMarker, newContent) {
    // We splitsen de tekst op de markers
    const parts = content.split(startMarker);
    if (parts.length < 2) return null; // Start marker niet gevonden
  
    const subParts = parts[1].split(endMarker);
    if (subParts.length < 2) return null; // Eind marker niet gevonden na de start
  
    // parts[0] = alles VOOR de start marker
    // subParts[1] = alles NA de eind marker
    // We bouwen het bestand opnieuw op:
    return [
      parts[0],
      startMarker,
      `\n${newContent}\n`,
      endMarker,
      subParts[1]
    ].join('');
  }
====
#!/usr/bin/env node
const fs = require('fs');
const path = require('path');
const logger = require('../utils/logger'); // De enige echte aanpassing
const backupConfigs = require('../utils/backup-helper');
const ROOT = path.resolve(__dirname, '../../');
const MAX_FILE_SIZE = 50000; // 50KB limiet uit ADR-06 [cite: 17]

const PATHS = {
  tsconfig: path.join(ROOT, 'tsconfig.json'),
  babel:    path.join(ROOT, 'babel.config.js'),
  jest:     path.join(ROOT, 'jest.config.js'),
  jsconfig: path.join(ROOT, 'jsconfig.json'),
};

function checkHardening(filePath) {
  if (fs.existsSync(filePath)) {
    const stats = fs.statSync(filePath);
    if (stats.size > MAX_FILE_SIZE) {
      // Gebruik de logger om de fatale fout uit de Commander te imiteren [cite: 18]
      logger.warn(`${logger.TEXT.FILE_TOO_LARGE} (${path.basename(filePath)}: ${stats.size} bytes)`);
      return false;
    }
  }
  return true;
}

async function main() {
  logger.startTimer(); // Start de klok
  logger.info(logger.TEXT.SYNC_START);
  backupConfigs();
  try {
    // ADR-06 Hardening Check [cite: 14]
    if (!checkHardening(PATHS.babel) || !checkHardening(PATHS.jest)) {
      logger.die(logger.TEXT.ADR_SAFETY_LIMIT);
    }

    const paths = parseTsConfig(PATHS.tsconfig);
    const entries = Object.entries(paths);
    logger.info(logger.TEXT.SYNC_ALIASES_FOUND(entries.length));

    // ... (Alias generatie logica) ...

    if (!logger.isDryRun) {
      // Hier schrijven we de bestanden echt
      // fs.writeFileSync(PATHS.babel, babelTemplate);
      logger.ok(logger.TEXT.SYNC_OK);
    } else {
      logger.ok(logger.TEXT.DRY_RUN_COMPLETE);
    }

  } catch (error) {
    logger.die(error.message);
  } finally {
    logger.stopTimer(); // Stop de klok en toon tijd
  }
}

// Helper blijft hetzelfde
function parseTsConfig(filePath) {
  const content = fs.readFileSync(filePath, 'utf8');
  const match = content.match(/"paths":\s*\{([\s\S]*?)\}/);
  if (!match) logger.die("tsconfig.json"); 
  return JSON.parse(`{${match[1].replace(/,\s*$/, "")}}`);
}

main();
====
const fs = require('fs');
const ts = require('typescript');

/**
 * Parsen van tsconfig.json met ondersteuning voor JSONC (comments)
 */
function parseTsConfig(configPath) {
  if (!fs.existsSync(configPath)) {
    throw new Error('CONFIG_NOT_FOUND');
  }

  const rawContent = fs.readFileSync(configPath, 'utf8');
  const result = ts.parseConfigFileTextToJson(configPath, rawContent);

  if (result.error) {
    throw new Error('CONFIG_PARSE_ERROR');
  }

  return result.config;
}

/**
 * Haalt aliassen uit tsconfig/jsconfig en maakt ze schoon
 */
function extractAliases(tsconfig, rootDir, reserved) {
  const rawPaths = (tsconfig.compilerOptions && tsconfig.compilerOptions.paths) || {};
  const cleanAliases = {};

  for (const [key, paths] of Object.entries(rawPaths)) {
    // Sla gereserveerde prefixes over
    if (reserved.some(prefix => key.startsWith(prefix))) continue;

    // Validatie van de data-structuur om 'replace' errors te voorkomen
    if (Array.isArray(paths) && paths.length > 0 && typeof paths[0] === 'string') {
      cleanAliases[key] = paths;
    }
  }

  return cleanAliases;
}

module.exports = { 
  extractAliases, 
  parseTsConfig 
};
=====
const path = require('path');

// --- SINGLE SOURCE OF TRUTH VOOR MARKERS ---
const TAG = "@alias-start"; // Verander dit hier, en het verandert overal
const END_TAG = "@alias-end";

const markers = {
  // We bouwen de markers dynamisch op zodat ze overal consistent zijn
  babel:    { start: `// ${TAG}`, end: `// ${END_TAG}` },
  jest:     { start: `// ${TAG}`, end: `// ${END_TAG}` },
  jsconfig: { start: `// ${TAG}`, end: `// ${END_TAG}` },
};

module.exports = {
  paths: {
    root: path.resolve(__dirname, '../../'),
    tsconfig: path.resolve(__dirname, '../../tsconfig.json'),
    babel: path.resolve(__dirname, '../../babel.config.js'),
    jest: path.resolve(__dirname, '../../jest.config.js'),
    jsconfig: path.resolve(__dirname, '../../jsconfig.json'),
  },
  
  markers,
  
  // Gereserveerde prefixes die we nooit als alias willen
  reservedPrefixes: ['http://', 'https://', './', '../'],

  flags: {
    dryRun: process.argv.includes('--dry-run'),
    verbose: process.argv.includes('--verbose'),
    backup: process.argv.includes('--backup'),
    restore: process.argv.includes('--restore'),
    help: process.argv.includes('--help'),
  }
}; 
====
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');
const logger = require('../utils/logger');

function generateKeysFile() {
    const allKeys = Object.keys(logger.TEXT).sort();
    
    // Header & Subheader uit de constants
    const header = logger.TEXT.KEYS_INDEX_NAME;
    const date = new Date().toLocaleString();
    const subHeader = logger.TEXT.KEYS_INDEX_GEN(date);
    
    // Maak een lijst: KEY -> Waarde (of [Function])
    const keyMap = allKeys.map(k => {
        const val = logger.TEXT[k];
        const displayVal = typeof val === 'function' ? '[Dynamische Functie]' : val;
        return `${k.padEnd(30)} | ${displayVal}`;
    });

    const content = `${header}\n${subHeader}\n${'-'.repeat(60)}\n${keyMap.join('\n')}`;
    fs.writeFileSync('keys.txt', content);
}

async function runStep(name, command) {
    logger.info(logger.TEXT.STEP_START(name));
    if (logger.isDryRun) {
        logger.ok(logger.TEXT.STEP_SKIP(command));
        return true;
    }
    try {
        execSync(command, { stdio: 'inherit' });
        return true;
    } catch (error) {
        logger.error(logger.TEXT.STEP_FAIL(name));
        return false;
    }
}

async function cleanupReports() {
    const reportDir = path.resolve(__dirname, '../../reports');
    if (!fs.existsSync(reportDir)) return;

    logger.info(logger.TEXT.CLEANUP_RUNNING);
    try {
        execSync('ls -t reports | tail -n +6 | xargs -I {} rm -rf reports/{} 2>/dev/null || true');
        logger.ok(logger.TEXT.CLEANUP_DONE);
    } catch (e) {
        logger.warn(logger.TEXT.CLEANUP_FAIL);
    }
}

async function main() {
    logger.startTimer();
    const REPORT_BASE = `reports/${new Date().toISOString().replace(/[:T]/g, '-').slice(0, 16)}`;

    // 1. Taken uitvoeren
    await runStep("Sanity Check", "node scripts/sync-aliases/index.js " + process.argv.slice(2).join(' '));
    await runStep("Deduplicatie", "bash scripts/maintenance/phoenix_dedup.sh src");
    await runStep("Project Audit", "bash scripts/maintenance/phoenix-check.sh");

    // 2. Opschonen
    await cleanupReports();

    // 3. Documentatie (De Keys indexeren)
    generateKeysFile(); 

    // 4. Afsluiten
    logger.info(logger.TEXT.FINISH);
    logger.report(REPORT_BASE); 
    logger.stopTimer();
}

main();
=====
#!/usr/bin/env bash
set -euo pipefail

# Bepaal de root van het project (rekenend vanaf scripts/maintenance/)
# dirname ${BASH_SOURCE[0]} geeft de map van het script zelf
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"

# Nu is het pad naar de bridge ALTIJD correct

log_info "COMMIT_START"

# 1) Opruimen
log_info "CLEAN_ARTIFACTS"
rm -rf artifacts compare_out dedup_reports || true

log_info "CLEAN_BAK"
find src -type f -name '*.bak.*' -delete 2>/dev/null || true

if [[ -d reports ]]; then
  log_info "CLEAN_REPORTS"
  ( cd reports && ls -1t | grep -v latest | tail -n +6 | xargs -r rm -rf ) 2>/dev/null || true
fi

# 2) Dev caches
if command -v npx >/dev/null 2>&1; then
  log_info "CLEAN_EXPO"
  # npx expo start -c >/dev/null 2>&1 || true
fi

# 3) Lint/TypeScript (non-fatal)
log_info "RUN_CHECKS"
npm run -s lint  >/dev/null 2>&1 || log_val "warn" "CHECK_ISSUE" "lint"
npx tsc --noEmit >/dev/null 2>&1 || log_val "warn" "CHECK_ISSUE" "type"

# 4) Git logica
branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo unknown)"
timestamp="$(date +'%Y-%m-%d_%H%M')"
tag="phoenix-${timestamp}"
commit_msg="chore: phoenix run ${timestamp} â€” audits green (A+) â€” cleanup & maintenance"

log_info "GIT_ADD"
git add -A

log_val "info" "GIT_COMMIT" "$commit_msg"
git commit -m "$commit_msg" || log_warn "GIT_COMMIT_NONE"

log_val "info" "GIT_TAG" "$tag"
git tag -f "${tag}" || true

log_info "GIT_PUSH"
git push --follow-tags || git push && git push --tags || true

log_val2 "ok" "COMMIT_DONE" "$branch" "$tag"
=====
#!/usr/bin/env bash
set -euo pipefail

# Fallback logging
if ! command -v log_info &> /dev/null; then
    log_info() { echo -e "â„¹ï¸  $1"; }
    log_ok() { echo -e "âœ… $1"; }
    log_val() { echo -e "ðŸ“Š $1: $2"; }
fi

log_info "PHOENIX_FINAL_SMASH_STARTING"

# Gecorrigeerde TARGETS gebaseerd op je tsconfig.json
TARGETS="domain|state|ui|styles|app|utils|services|assets|logic|config|context|selectors|shared-types|components|fields"
# Zoek alle bestanden met relatieve imports
FILES=$(grep -rE "from ['\"]\.\.?/" src --include="*.ts" --include="*.tsx" -l || true)

for file in $FILES; do
    # We gebruiken een tijdelijk bestand om de sed 'can't read' errors te voorkomen
    # Dit werkt op elk systeem (macOS/Linux)
    sed -E "s#(['\"])(\.\.?/)+($TARGETS)#\1@\3#g" "$file" > "$file.tmp" && mv "$file.tmp" "$file"

    # Specifieke buren-fix voor de state/schemas map die we zagen
    if [[ "$file" == *"src/state/schemas/"* ]]; then
        sed -E "s#from (['\"])\.\./#from \1@state/schemas/#g" "$file" > "$file.tmp" && mv "$file.tmp" "$file"
    fi

    # Specifieke buren-fix voor services
    if [[ "$file" == *"src/services/"* ]]; then
        sed -E "s#from (['\"])(\./)(logger|storage)#from \1@services/\3#g" "$file" > "$file.tmp" && mv "$file.tmp" "$file"
    fi

    log_ok "Phoenix Treatment applied to: $(basename "$file")"
done

log_val "SUCCESS" "Imports hersteld"
====
const fs = require('fs');
const path = require('path');

// Het pad naar waar de logger Ã©cht staat
const LOGGER_SOURCE = path.join('src', 'services', 'logger');

// Functie om mappen recursief te doorzoeken
function getAllFiles(dirPath, arrayOfFiles) {
  const files = fs.readdirSync(dirPath);
  arrayOfFiles = arrayOfFiles || [];

  files.forEach(function(file) {
    if (fs.statSync(dirPath + '/' + file).isDirectory()) {
      if (file !== 'node_modules' && file !== '.git') {
        arrayOfFiles = getAllFiles(dirPath + '/' + file, arrayOfFiles);
      }
    } else {
      // Check alleen .ts en .tsx bestanden
      if (file.endsWith('.ts') || file.endsWith('.tsx')) {
        arrayOfFiles.push(path.join(dirPath, file));
      }
    }
  });

  return arrayOfFiles;
}

function fixImports() {
  const allFiles = getAllFiles(__dirname);
  let fixedCount = 0;

  allFiles.forEach(filePath => {
    let content = fs.readFileSync(filePath, 'utf8');

    // 1. Check of 'logger.' wordt gebruikt
    if (content.includes('logger.') && !content.includes('class Logger')) {
      
      // 2. Check of hij al geÃ¯mporteerd is
      if (!content.includes('import { logger }') && !content.includes('import {logger}')) {
        
        // 3. Bereken het relatieve pad van dit bestand naar de logger
        const dirOfFile = path.dirname(filePath);
        const absLoggerPath = path.join(__dirname, LOGGER_SOURCE);
        
        let relativePath = path.relative(dirOfFile, absLoggerPath);
        
        // Windows backslashes vervangen door forward slashes
        relativePath = relativePath.split(path.sep).join('/');
        
        // Zorg dat het begint met ./ of ../
        if (!relativePath.startsWith('.')) {
          relativePath = './' + relativePath;
        }

        // 4. Voeg de import toe bovenaan
        const importStatement = `import { logger } from '${relativePath}';\n`;
        
        console.log(`âœ… Fixed: ${path.basename(filePath)} -> import from '${relativePath}'`);
        
        fs.writeFileSync(filePath, importStatement + content);
        fixedCount++;
      }
    }
  });

  console.log(`\nklaar! ${fixedCount} bestanden gerepareerd.`);
}

fixImports();
====
#!/usr/bin/env bash
set -eo pipefail


TARGETS=("jest.config.js|50" "babel.config.js|50" "tsconfig.json|100" "package.json|200")
MAX_FAIL=0

log_info "GUARD_CHECK"

# --- Stap 1: File Size Checks ---
for entry in "${TARGETS[@]}"; do
  IFS="|" read -r FILE MAX_KB <<< "$entry"
  if [ -f "$FILE" ]; then
    SIZE_BYTES=$(date -r "$FILE" +%s 2>/dev/null || stat -c%s "$FILE" 2>/dev/null || stat -f%z "$FILE")
    SIZE_KB=$((SIZE_BYTES / 1024))
    if [ "$SIZE_KB" -gt "$MAX_KB" ]; then
      log_val3 "error" "GUARD_FAIL" "$FILE" "$SIZE_KB" "$MAX_KB"
      MAX_FAIL=1
    else
      log_val2 "ok" "GUARD_PASS" "$FILE" "$SIZE_KB"
    fi
  fi
done

# --- Stap 2: Preset Check & Auto-fix ---
log_info "PRESET_CHECK"
if ! grep -q "metro-react-native-babel-preset" package.json; then
    log_err "ERR_BABEL_PRESET"
    log_info "REMEDY_BABEL"
    
    # Phoenix-stijl: Probeer het zelf op te lossen
    if npm install --save-dev metro-react-native-babel-preset; then
        log_ok "DEDUP_OK" # Misbruik even een 'success' key of maak een nieuwe
        MAX_FAIL=0
    else
        MAX_FAIL=1
    fi
fi

# --- Stap 3: Finale ---
if [ "$MAX_FAIL" -eq 1 ]; then
  log_err "GUARD_CRITICAL"
  exit 1
fi

log_ok "GUARD_SAFE"
exit 0
=====
#!/usr/bin/env bash
set -euo pipefail

# phoenix_compare.sh â€” Geoptimaliseerd voor Cloud Shell / Containers
# - Geen sudo nodig
# - Negeert node_modules/.git voor snelheid
# - Gebruikt grep voor binary detectie (geen 'file' command nodig)

usage() {
  cat <<'USAGE'
Gebruik: ./phoenix_compare.sh <DIR_A> <DIR_B> [--out OUTDIR] [--keywords "kw1,kw2"]

Opties:
  --out OUTDIR       Map voor rapporten (default: ./compare_out)
  --keywords LIST    Komma-gescheiden lijst (default: "phoenix")
  --all              Negeer 'node_modules' en '.git' NIET (standaard wel)

USAGE
}

# ---- Configuratie ----
OUTDIR="./compare_out"
KEYWORDS="phoenix"
IGNORE_SYSTEM_DIRS=true

# ---- Args parsing ----
if [[ $# -lt 2 ]]; then usage; exit 2; fi
DIR_A="$1"; shift
DIR_B="$1"; shift

while [[ $# -gt 0 ]]; do
  case "$1" in
    --out)      OUTDIR="$2"; shift 2;;
    --keywords) KEYWORDS="$2"; shift 2;;
    --all)      IGNORE_SYSTEM_DIRS=false; shift;;
    -h|--help)  usage; exit 0;;
    *)          echo "Onbekende optie: $1" >&2; usage; exit 2;;
  esac
done

# ---- Dependency Check (No Sudo fix) ----
require_cmd() {
  if ! command -v "$1" &> /dev/null; then
    echo "âŒ Fout: Commando '$1' niet gevonden. Dit script vereist coreutils." >&2
    exit 1
  fi
}

require_cmd "stat"
require_cmd "grep"
require_cmd "awk"
require_cmd "diff"

# Check hashing tool (sha256sum of shasum)
if command -v sha256sum &> /dev/null; then
  HASHER="sha256sum"
elif command -v shasum &> /dev/null; then
  HASHER="shasum -a 256"
else
  echo "âš ï¸ Geen sha256sum gevonden, vallend terug op md5sum..."
  require_cmd "md5sum"
  HASHER="md5sum"
fi

# ---- Validatie ----
for d in "$DIR_A" "$DIR_B"; do
  if [[ ! -d "$d" ]]; then echo "âŒ Fout: map bestaat niet: $d" >&2; exit 1; fi
done
mkdir -p "$OUTDIR"

INDEX_A="$OUTDIR/index_A.tsv"
INDEX_B="$OUTDIR/index_B.tsv"
CSV="$OUTDIR/compare_report.csv"
MD="$OUTDIR/compare_report.md"

# ---- Helpers ----

# Veilig tekst detecteren zonder 'file' commando
is_text_file() {
  # grep -I behandelt binaire bestanden als non-match en crasht niet
  if grep -qI "." "$1" 2>/dev/null || [[ ! -s "$1" ]]; then
    return 0 # Tekst (of leeg)
  else
    return 1 # Binair
  fi
}

has_keyword() {
  # $1=file path, $2=keywords
  local f="$1"; local kws="$2"
  # Alleen zoeken in tekstbestanden
  if is_text_file "$f"; then
    local pattern
    # Zet komma's om naar pipes voor grep -E (kw1|kw2)
    pattern=$(echo "$kws" | sed 's/,/|/g')
    if grep -I -i -E -q "$pattern" "$f"; then
      echo "yes"; return 0
    fi
  fi
  echo "no"; return 1
}

index_dir() {
  local root="$1"; local out="$2"
  echo -e "dir\trelpath\tbasename\tsize\tmtime_epoch\tmtime_iso\tis_text\thash\tphx" > "$out"
  
  # Bouw find commando op
  local find_cmd=(find "$root" -type f)
  
  if [[ "$IGNORE_SYSTEM_DIRS" == "true" ]]; then
    # Prune node_modules en .git voor performance
    find_cmd=(find "$root" -type d \( -name "node_modules" -o -name ".git" -o -name ".firebase" \) -prune -o -type f -print)
  fi

  "${find_cmd[@]}" | while IFS= read -r f; do
    local rel=${f#"$root/"}
    local base=$(basename "$f")
    
    # Stat (Linux/GNU syntax, standaard in Firebase/Cloud Shell)
    local size epoch iso
    size=$(stat -c "%s" "$f")
    epoch=$(stat -c "%Y" "$f")
    iso=$(date -u -d "@$epoch" +"%Y-%m-%dT%H:%M:%SZ" 2>/dev/null || echo "Unknown")

    # Hash & Type
    local hash=$($HASHER "$f" | awk '{print $1}')
    local is_txt="binary"
    if is_text_file "$f"; then is_txt="text"; fi
    
    local phx=$(has_keyword "$f" "$KEYWORDS")
    
    printf "%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n" \
      "$root" "$rel" "$base" "$size" "$epoch" "$iso" "$is_txt" "$hash" "$phx" >> "$out"
  done
}

# ---- Uitvoering ----
echo "ðŸ” Indexeren van $DIR_A..."
index_dir "$DIR_A" "$INDEX_A"
echo "ðŸ” Indexeren van $DIR_B..."
index_dir "$DIR_B" "$INDEX_B"

echo "ðŸ“Š Vergelijken en rapport genereren..."

# CSV Header
echo "kind,a_relpath,b_relpath,a_basename,b_basename,status,newest,a_mtime,b_mtime,a_type,b_type,a_phx,b_phx" > "$CSV"

# 1. Name Match Logic (Basename based)
awk -F"\t" 'NR==1{next} FNR==NR{ a[$3] = $0; next }
{ if ($3 in a) { print a[$3] "\t" $0 } }' "$INDEX_A" "$INDEX_B" | \
while IFS=$'\t' read -r a_dir a_rel a_base a_size a_epoch a_iso a_txt a_hash a_phx \
                      b_dir b_rel b_base b_size b_epoch b_iso b_txt b_hash b_phx; do
  
  status="different"
  if [[ "$a_hash" == "$b_hash" ]]; then
    status="identical"
  elif [[ "$a_txt" == "text" && "$b_txt" == "text" ]]; then
     # Quick diff check (exit code 0 = same, 1 = diff)
     if diff -q "$a_dir/$a_rel" "$b_dir/$b_rel" >/dev/null 2>&1; then
        status="identical" # Zou al door hash gedekt moeten zijn, maar voor de zekerheid
     else
        status="different"
     fi
  else
     status="binary_diff"
  fi

  newest="equal"
  if (( a_epoch > b_epoch )); then newest="A"; elif (( b_epoch > a_epoch )); then newest="B"; fi

  echo "name_match,$a_rel,$b_rel,$a_base,$b_base,$status,$newest,$a_iso,$b_iso,$a_txt,$b_txt,$a_phx,$b_phx" >> "$CSV"
done

# 2. Content Match Logic (Hash based, different name)
awk -F"\t" 'NR==1{next} FNR==NR{ a[$8] = a[$8] "\n" $0; next }
{ if ($8 in a) { 
    split(a[$8], lines, "\n")
    for (i in lines) { if (length(lines[i])>0) print lines[i] "\t" $0 }
  }
}' "$INDEX_A" "$INDEX_B" | \
while IFS=$'\t' read -r a_dir a_rel a_base a_size a_epoch a_iso a_txt a_hash a_phx \
                      b_dir b_rel b_base b_size b_epoch b_iso b_txt b_hash b_phx; do
  
  # Skip als het ook een naam-match is (die hebben we al gehad)
  if [[ "$a_base" == "$b_base" ]]; then continue; fi

  newest="equal"
  if (( a_epoch > b_epoch )); then newest="A"; elif (( b_epoch > a_epoch )); then newest="B"; fi

  echo "content_match,$a_rel,$b_rel,$a_base,$b_base,identical,$newest,$a_iso,$b_iso,$a_txt,$b_txt,$a_phx,$b_phx" >> "$CSV"
done

# ---- Markdown Rapport ----
T_A=$(awk 'NR>1{c++}END{print c+0}' "$INDEX_A")
T_B=$(awk 'NR>1{c++}END{print c+0}' "$INDEX_B")
N_MATCH=$(grep -c "^name_match" "$CSV" || true)
C_MATCH=$(grep -c "^content_match" "$CSV" || true)
DIFFS=$(grep -c ",different" "$CSV" || true)
PHX_A=$(awk -F, '$12=="yes"{c++}END{print c+0}' "$CSV")
PHX_B=$(awk -F, '$13=="yes"{c++}END{print c+0}' "$CSV")

cat > "$MD" <<EOF
# ðŸ¦… Phoenix Vergelijkingsrapport

| Bron | Pad | Bestanden | Phoenix Keywords |
|------|-----|-----------|------------------|
| **A** | \`$DIR_A\` | $T_A | $PHX_A |
| **B** | \`$DIR_B\` | $T_B | $PHX_B |

**Gegenereerd:** $(date -u +"%Y-%m-%d %H:%M UTC")

## ðŸ“Š Resultaten
- **Naam Matches:** $N_MATCH (Bestanden met dezelfde naam in beide mappen)
- **Inhoud Matches:** $C_MATCH (Verplaatst/Hernoemd maar zelfde inhoud)
- **Verschillen:** $DIFFS (Bestanden met dezelfde naam maar andere inhoud)

## ðŸ“‚ Details
Zie \`compare_report.csv\` voor de ruwe data.

### Top 10 Recente Verschillen (Nieuwste eerst)
| Bestand (A) | Status | Nieuwste |
|-------------|--------|----------|
$(grep ",different" "$CSV" | head -10 | awk -F, '{printf "| %s | %s | %s |\n", $2, $6, $7}')

===
EOF

echo "âœ… Klaar! Rapporten opgeslagen in: $OUTDIR"
ls -l "$OUTDIR"
=====
#!/usr/bin/env bash
# Phoenix Deduplicatie â€” Key-driven Editie
set -euo pipefail

# Importeer de bridge

# Gebruik de centrale keys uit audit.js
log_info "DEDUP_START"

TARGET_DIR="${1:-src}"

if [[ -d "$TARGET_DIR" ]]; then
    # Hier komt de functionele logica van je dedup script [cite: 15]
    # We simuleren hier even de run:
    mkdir -p dedup_reports
    touch dedup_reports/scan.txt
    
    log_info "DEDUP_REPORT_MOVE"
    # De orchestrator verplaatst dit later naar de juiste plek [cite: 16]
    
    log_ok "DEDUP_OK"
else
    log_warn "DEDUP_SKIP"
fi
=====
#!/usr/bin/env bash
set -euo pipefail

# 1. Bridge laden

# 2. Lock-logica (Voorkomt dat de audit twee keer tegelijk draait)
REPO_ROOT="$(git rev-parse --show-toplevel 2>/dev/null || pwd)"
REPO_NAME="$(basename "$REPO_ROOT")"
LOCKDIR="/tmp/phoenix.audit.lock.${REPO_NAME}.$(id -u)"
LOCK_FILE="$LOCKDIR/started"

if mkdir "$LOCKDIR" 2>/dev/null; then
  echo "$$" > "$LOCKDIR/pid"
  date > "$LOCKDIR/started"
  trap 'rm -rf "$LOCKDIR"' EXIT
else
  if [[ -f "$LOCK_FILE" ]]; then
    NOW="$(date +%s)"
    STARTED_TS=$(date -r "$LOCK_FILE" +%s 2>/dev/null || stat -f%m "$LOCK_FILE" 2>/dev/null || echo 0)
    if [[ "$NOW" -gt $(( STARTED_TS + 1800 )) ]]; then
      log_warn "LOCK_STALE"
      rm -rf "$LOCKDIR"
      exec "$0" "$@"
    fi
  fi
  log_err "LOCK_ACTIVE"
  exit 1
fi

# 3. Modules laden (Stil, tenzij verbose)
log_info "AUDIT_START"
set +u
source ".phoenix/core.sh"
source ".phoenix/checkers.sh"
source ".phoenix/extractors.sh"
source ".phoenix/audits.sh"
source ".phoenix/reports.sh"
set -u

#!/usr/bin/env bash
set -euo pipefail

# 1. Bridge laden

main() {
    # Alleen loggen als we NIET vanuit de orchestrator komen (voorkomt dubbel-log)
    if [[ "${PHOENIX_INTERNAL:-false}" != "true" ]]; then
        log_info "AUDIT_START"
    fi

    local start_time=$(date +%s)
    local _audit_exit_code=0
    
    # Voer de audits uit (deze functies komen uit .phoenix/audits.sh)
    run_all_audits || _audit_exit_code=$? 

    # Toon de samenvatting (A+ score)
    if declare -f show_summary > /dev/null; then
        show_summary
    else
        log_err "AUDIT_SUMMARY_FAIL"
        _audit_exit_code=1
    fi

    # Timer berekenen
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))

    # Tijd loggen via de bridge
    node -e "const l=require('./scripts/utils/logger'); \
      const msg = typeof l.TEXT.FINISH_TIME === 'function' ? l.TEXT.FINISH_TIME('$duration') : l.TEXT.FINISH_TIME; \
      l.info(msg);"

    # Bepaal exit status
    if [[ "${SOFT_FAIL:-false}" == "true" ]]; then
        exit 0
    else
        exit $_audit_exit_code
    fi
}

main "$@"
=====

#!/usr/bin/env bash
set -euo pipefail

# Ga naar projectroot (zeker doen als dit script vanuit CI of andere mappen draait)
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
cd "$ROOT_DIR"

# Gebruik de package manager die je gebruikt (npm/pnpm/yarn)
npm run sync:aliases

